{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè° Min-Max Normalization Workshop\n",
    "## Team Name: \n",
    "## Team Members: \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùó Why We Normalize: The Problem with Raw Feature Scales\n",
    "\n",
    "In housing data, features like `Price` and `Lot_Size` can have values in the hundreds of thousands, while others like `Num_Bedrooms` range from 1 to 5. This creates problems when we use algorithms that depend on numeric magnitudes.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è What Goes Wrong Without Normalization\n",
    "\n",
    "---\n",
    "\n",
    "### 1. üß≠ K-Nearest Neighbors (KNN)\n",
    "\n",
    "KNN uses the **Euclidean distance** formula:\n",
    "\n",
    "$$\n",
    "d = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2 + \\cdots}\n",
    "$$\n",
    "\n",
    "**Example:**\n",
    "\n",
    "- $ \\text{Price}_1 = 650{,}000, \\quad \\text{Price}_2 = 250{,}000 $\n",
    "- $ \\text{Bedrooms}_1 = 3, \\quad \\text{Bedrooms}_2 = 2 $\n",
    "\n",
    "Now compute squared differences:\n",
    "\n",
    "$$\n",
    "(\\text{Price}_1 - \\text{Price}_2)^2 = (650{,}000 - 250{,}000)^2 = (400{,}000)^2 = 1.6 \\times 10^{11}\n",
    "$$\n",
    "$$\n",
    "(\\text{Bedrooms}_1 - \\text{Bedrooms}_2)^2 = (3 - 2)^2 = 1\n",
    "$$\n",
    "\n",
    "‚û°Ô∏è **Price dominates the distance calculation**, making smaller features like `Bedrooms` irrelevant.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. üìâ Linear Regression\n",
    "\n",
    "Linear regression estimates:\n",
    "\n",
    "$$\n",
    "y = \\beta_1 \\cdot \\text{Price} + \\beta_2 \\cdot \\text{Bedrooms} + \\beta_3 \\cdot \\text{Lot\\_Size} + \\epsilon\n",
    "$$\n",
    "\n",
    "If `Price` has very large values:\n",
    "- Gradient updates for $ \\beta_1 $ will be **much larger**\n",
    "- Gradient updates for $ \\beta_2 $ (Bedrooms) will be **very small**\n",
    "\n",
    "‚û°Ô∏è The model overfits high-magnitude features like `Price`.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. üß† Neural Networks\n",
    "\n",
    "A single neuron computes:\n",
    "\n",
    "$$\n",
    "z = w_1 \\cdot \\text{Price} + w_2 \\cdot \\text{Bedrooms} + w_3 \\cdot \\text{Lot\\_Size}\n",
    "$$\n",
    "\n",
    "If:\n",
    "\n",
    "- $ \\text{Price} = 650{,}000 $\n",
    "- $ \\text{Bedrooms} = 3 $\n",
    "- $ \\text{Lot\\_Size} = 8{,}000 $\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "z \\approx w_1 \\cdot 650{,}000 + w_2 \\cdot 3 + w_3 \\cdot 8{,}000\n",
    "$$\n",
    "\n",
    "‚û°Ô∏è Even with equal weights, `Price` contributes **most of the activation**, making it difficult for the network to learn from other features.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Solution: Min-Max Normalization\n",
    "\n",
    "We apply the transformation:\n",
    "\n",
    "$$\n",
    "x_{\\text{normalized}} = \\frac{x - x_{\\text{min}}}{x_{\\text{max}} - x_{\\text{min}}}\n",
    "$$\n",
    "\n",
    "This scales all features to a common range (typically $[0, 1]$).\n",
    "\n",
    "| Feature      | Raw Value | Min     | Max     | Normalized Value |\n",
    "|--------------|-----------|---------|---------|------------------|\n",
    "| Price        | 650,000   | 250,000 | 800,000 | 0.72             |\n",
    "| Bedrooms     | 3         | 1       | 5       | 0.50             |\n",
    "| Lot_Size     | 8,000     | 3,000   | 10,000  | 0.714            |\n",
    "\n",
    "‚û°Ô∏è Now, **each feature contributes fairly** to model training or distance comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Use Case: Housing Data\n",
    "We are normalizing features from a real estate dataset to prepare it for machine learning analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¢ Load and display dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('housing_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé Step 1 ‚Äî Implement Min-Max Normalization on the Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úçÔ∏è Implement Min-Max Normalization manually here (no sklearn/numpy)\n",
    "# Normalize: Price, Area_sqft, Num_Bedrooms, Num_Bathrooms, Lot_Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîé Talking Point 1 ‚Äî [Insert your review comment here]\n",
    "\n",
    "Reviwed by:\n",
    "- Name\n",
    "- Name\n",
    "- Name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
